{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "firstrun = True\n",
        "\n",
        "if firstrun != False:\n",
        "  !pip install fredapi\n",
        "  !pip install matplotlib\n",
        "  !pip install plotly\n",
        "  !pip install keras\n",
        "\n",
        "  from fredapi import Fred\n",
        "  fred = Fred(api_key='63769be4fe08f91aef948b301151587d')\n",
        "  import yfinance as yf\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install keras-tuner --upgrade\n",
        "import keras_tuner\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "from matplotlib.ticker import MaxNLocator"
      ],
      "metadata": {
        "id": "d5xbIZHsbgJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c576cb28-acac-4f03-e9b7-2d52724ddb52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fredapi\n",
            "  Downloading fredapi-0.5.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fredapi) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->fredapi) (1.16.0)\n",
            "Installing collected packages: fredapi\n",
            "Successfully installed fredapi-0.5.1\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.5-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras-tuner)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (13.6.0)\n",
            "Collecting namex (from keras-core->keras-tuner)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n",
            "Installing collected packages: namex, kt-legacy, keras-core, keras-tuner\n",
            "Successfully installed keras-core-0.1.7 keras-tuner-1.4.5 kt-legacy-1.0.5 namex-0.0.7\n",
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(ticker_symbol,startday,endday):\n",
        "  we_stock_data = yf.download(ticker_symbol, start=startday, end=endday)\n",
        "  we_daily_returns = we_stock_data['Adj Close'].pct_change() * 100\n",
        "  we_stock_data['Daily_Return'] = we_stock_data['Adj Close'].pct_change() * 100\n",
        "\n",
        "  CPI = fred.get_series('MEDCPIM158SFRBCLE',observation_start=startday)\n",
        "  M30US = fred.get_series('MORTGAGE30US',observation_start=startday)\n",
        "  UNRA = fred.get_series('UNRATE',observation_start=startday)\n",
        "  SP500 = fred.get_series('SP500',observation_start=startday)\n",
        "  NEWH = fred.get_series('HOUST',observation_start=startday)\n",
        "  NASDAQ = fred.get_series('NASDAQCOM',observation_start=startday)\n",
        "  CARSA = fred.get_series('TOTALSA',observation_start=startday)\n",
        "\n",
        "  df = {}\n",
        "  df = pd.concat([SP500, CPI, M30US, UNRA, NEWH, NASDAQ, CARSA], axis=1)\n",
        "  data_names = ['SP500', 'CPI', 'M30US', 'UNRA', 'NEWH', 'NASDAQ', 'CARSA']\n",
        "  df.columns = data_names\n",
        "\n",
        "  df = df.ffill()\n",
        "  df = df.fillna(method = 'ffill')\n",
        "  df = df.fillna(method = 'backfill')\n",
        "  we_stock_data = we_stock_data.ffill()\n",
        "  we_stock_data = we_stock_data.fillna(method = 'ffill')\n",
        "  we_stock_data = we_stock_data.fillna(method = 'backfill')\n",
        "  we = pd.concat((we_stock_data, df),axis=1)\n",
        "  we.dropna(inplace=True)\n",
        "  we.to_csv('data.csv', index=False)\n",
        "\n",
        "  return we"
      ],
      "metadata": {
        "id": "DIl5M564LawA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataog = getData('BAC','2022-01-01','2023-11-05')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S2qMlZSMDT5",
        "outputId": "0bdb9840-0660-4f1f-bb63-db4f2d1f66c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MJRbFpDCbRpZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "e48691c9-913f-4db5-f7c1-fa1697b11fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2023-10-30', '2023-10-31', '2023-11-01', '2023-11-02',\n",
            "               '2023-11-03'],\n",
            "              dtype='datetime64[ns]', freq=None)\n",
            "(463, 14)\n",
            "(456, 3, 14)\n",
            "(456, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e80945ba4489>:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(X), np.array(y), date, datepred, np.array(xpred)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e80945ba4489>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m  \u001b[0;31m#print(date[i],x[i,:,target_col], y[i], orig[i+seq_length])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatepred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mtestsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 3 were indexed"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#data = pd.read_csv('wedata22-23.csv')\n",
        "data = dataog\n",
        "seq_length = 3\n",
        "target_coln = 'Close'\n",
        "dayspan = 10\n",
        "\n",
        "target_col = data.columns.get_loc(target_coln)\n",
        "date = data.index\n",
        "print(date[-5:])\n",
        "\n",
        "'''\n",
        "data = [[t1,x1],[t2,x2],[t3,x3]]\n",
        "'''\n",
        "\n",
        "scalerinput = MinMaxScaler()\n",
        "scaleroutput = MinMaxScaler()\n",
        "orig = data[target_coln]\n",
        "scaleroutput.fit(data[target_coln].values.reshape(-1,1))\n",
        "data = scalerinput.fit_transform(data)\n",
        "df = pd.DataFrame()\n",
        "df[0] = [1,2,3,4,5,6,7]\n",
        "df[1] = [11,22,33,44,55,66,77]\n",
        "print(data.shape)\n",
        "def create_sequences(data, seq_length, target_col, nextdays,date):\n",
        "    datepred = date[-nextdays:]\n",
        "    date = date[seq_length-1:-nextdays]\n",
        "    X, y, xpred = [], [], []\n",
        "    data = pd.DataFrame(data)  # Convert the data to a DataFrame for column referencing\n",
        "    for i in range(len(data) - seq_length - nextdays + 1):\n",
        "        X.append(data.iloc[i:i+seq_length, :].values)  # Use all columns as input\n",
        "        y_sequence = [data.iloc[i+seq_length+j, target_col] for j in range(nextdays)]\n",
        "        y.append(y_sequence)\n",
        "    for i in range(nextdays):\n",
        "        xpred.append(data.iloc[i-nextdays:i+seq_length, :].values)  # Use all columns as input\n",
        "\n",
        "    return np.array(X), np.array(y), date, datepred, np.array(xpred)\n",
        "\n",
        "nextdays = 5\n",
        "x , y , date, datepred, xpred = create_sequences(data,seq_length,target_col,nextdays,date)\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "###para regresar inverse escalado####\n",
        "#y = scaleroutput.inverse_transform(y)\n",
        "#for i in range(x.shape[1]):\n",
        " # x[:,i,:] = scalerinput.inverse_transform(x[:,i,:])\n",
        "##for i in range(x.shape[0]):\n",
        " #print(date[i],x[i,:,target_col], y[i], orig[i+seq_length])\n",
        "for i in range(nextdays):\n",
        " print(datepred[i],xpred[i,:,target_col])\n",
        "\n",
        "testsize = int(np.round(x.shape[0]*.1))\n",
        "trainsize = int(np.round((x.shape[0]-testsize)*.9))\n",
        "x_train = x[:trainsize,:,:]\n",
        "y_train = y[:trainsize,:]\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_val = x[trainsize:-testsize,:,:]\n",
        "y_val = y[trainsize:-testsize,:]\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "x_test = x[-testsize:,:,:]\n",
        "y_test = y[-testsize:,:]\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "datetrain = date[:trainsize]\n",
        "dateval = date[trainsize:-testsize]\n",
        "datetest = date[-testsize:]\n",
        "print(datetrain.shape)\n",
        "print(dateval.shape)\n",
        "print(datetest.shape)\n",
        "print(date.shape)\n",
        "print(datetrain.shape[0]+dateval.shape[0]+datetest.shape[0])\n",
        "\n",
        "plt.plot(datetrain,x_train[:,-1,target_col])\n",
        "plt.plot(dateval,x_val[:,-1,target_col])\n",
        "plt.plot(datetest,x_test[:,-1,target_col])\n",
        "plt.figure()\n",
        "plt.plot(date[:],x[:,-1,target_col])\n",
        "\n",
        "TimeSteps=x_train.shape[1]\n",
        "TotalFeatures=x_train.shape[2]\n",
        "\n",
        "'''\n",
        "for i in range(x.shape[0]):\n",
        "  print(x[i,:,target_col], y[i])\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "train = data\n",
        "test = train.tail(dayspan+seq_length+1)\n",
        "test = test.reset_index(drop=True)\n",
        "train = train.iloc[:-dayspan]\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "val = train.tail(valsize+seq_length+1)\n",
        "val = val.reset_index(drop=True)\n",
        "train = train.iloc[:-valsize]\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "date = data.index\n",
        "datetest = date[-(dayspan+seq_length+1):]\n",
        "dateval = val.index\n",
        "datetrain = date[:-dayspan]\n",
        "dateval = datetrain[-(valsize+seq_length+1):]\n",
        "datetrain = datetrain[:-valsize]\n",
        "\n",
        "plt.plot(datetrain[-10:],train[target_coln][-10:])\n",
        "plt.plot(dateval,val[target_coln])\n",
        "plt.plot(datetest,test[target_coln])\n",
        "\n",
        "dataoutput = data[target_coln].values.reshape(-1,1)\n",
        "dataoutput = np.append(dataoutput, [[0]], axis=0)\n",
        "scaleroutput.fit(dataoutput)\n",
        "trainscaled = scalerinput.fit_transform(train)\n",
        "testscaled = scalerinput.transform(test)\n",
        "valscaled = scalerinput.transform(val)\n",
        "\n",
        "x_train, y_train = create_sequences(trainscaled, seq_length, target_col)\n",
        "x_test, y_test = create_sequences(testscaled, seq_length, target_col)\n",
        "x_val, y_val = create_sequences(valscaled, seq_length, target_col)\n",
        "\n",
        "TimeSteps=x_train.shape[1]\n",
        "TotalFeatures=x_train.shape[2]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = Sequential()\n",
        "\n",
        "regressor.add(LSTM(units = 32, activation = 'relu', input_shape = (TimeSteps, TotalFeatures), return_sequences=False))\n",
        "regressor.add(Dense(units = 15,activation = 'relu'))\n",
        "regressor.add(Dense(units = 15,activation = 'relu'))\n",
        "#regressor.add(LSTM(units = 10, activation = 'relu', input_shape = (TimeSteps, TotalFeatures), return_sequences=True))\n",
        "#regressor.add(LSTM(units = 5, activation = 'relu', return_sequences=False ))\n",
        "regressor.add(Dense(units = nextdays))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "regressor.compile(optimizer=opt, loss='mean_absolute_error',metrics=['mean_absolute_error'])\n",
        "early_stop = EarlyStopping(monitor='loss', patience=30, restore_best_weights=True)\n",
        "\n",
        "StartTime=time.time()\n",
        "history = regressor.fit(x_train, y_train, epochs=500, batch_size=10, validation_data=(x_val,y_val), verbose=2)#,callbacks=[early_stop]\n",
        "EndTime=time.time()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(75, activation='relu', input_shape=(TimeSteps, TotalFeatures)))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(nextdays))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "model.compile(optimizer=opt, loss='mean_squared_error',metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True)\n",
        "history = model.fit(x_train, y_train, epochs=500, batch_size=64,validation_data=(x_val,y_val),callbacks=[early_stop])#, validation_split=0.3\n",
        "'''\n",
        "print(\"## Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ##')\n",
        "\n",
        "stopped_epoch = early_stop.stopped_epoch\n",
        "best_epoch = stopped_epoch - early_stop.patience if early_stop.stopped_epoch is not None else None\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
        "plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
        "plt.axvline(x=best_epoch, color='r', linestyle='--', label='Early Stopping Epoch')\n",
        "plt.title('Training and Validation MAE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('mean_absolute_error')\n",
        "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True)) # Ensure integer values on x-axis\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "#plt.axvline(x=best_epoch, color='r', linestyle='--', label='Early Stopping Epoch')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "M_9TagncBGts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_Price = regressor.predict(x_train)\n",
        "print(predicted_Price.shape)\n",
        "print(predicted_Price)\n",
        "predicted_Price= scaleroutput.inverse_transform(predicted_Price)\n",
        "print(predicted_Price.shape)\n",
        "print(predicted_Price)\n",
        "plt.figure()\n",
        "plt.plot(datetrain,predicted_Price[:,0],label='Pred')\n",
        "plt.plot(datetrain,scaleroutput.inverse_transform(y_train)[:,0],label='Real')\n",
        "plt.legend()\n",
        "#plt.ylim(0, np.max(orig[2:trainsize]))\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "predicted_Price = regressor.predict(x_val)\n",
        "predicted_Price= scaleroutput.inverse_transform(predicted_Price)\n",
        "print(predicted_Price.shape)\n",
        "plt.figure()\n",
        "plt.plot(dateval,predicted_Price[:,0],label='Pred')\n",
        "plt.plot(dateval,scaleroutput.inverse_transform(y_val)[:,0],label='Real')\n",
        "plt.legend()\n",
        "#plt.ylim(0, np.max(orig[trainsize+2:-testsize]))\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "predicted_Price = regressor.predict(x_test)\n",
        "predicted_Price= scaleroutput.inverse_transform(predicted_Price)\n",
        "print(predicted_Price.shape)\n",
        "plt.figure()\n",
        "plt.plot(datetest,predicted_Price[:,0],label='Pred1')\n",
        "plt.plot(datetest[1:],predicted_Price[:-1,1],label='Pred2')\n",
        "plt.plot(datetest[2:],predicted_Price[:-2,2],label='Pred3')\n",
        "plt.plot(datetest,scaleroutput.inverse_transform(y_test)[:,-1],label='Real')\n",
        "plt.legend()\n",
        "#plt.ylim(0, np.max(orig[-testsize:]))\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predicted_Price = model.predict(x_train)\n",
        "predicted_Price= scaleroutput.inverse_transform(predicted_Price)\n",
        "print(predicted_Price.shape)\n",
        "print(predicted_Price)\n",
        "plt.figure()\n",
        "plt.plot(datetrain,predicted_Price,label='Pred')\n",
        "plt.plot(datetrain,scaleroutput.inverse_transform(y_train),label='Real')\n",
        "plt.legend()\n",
        "#plt.ylim(0, np.max(orig[2:trainsize]))\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "predicted_Price = model.predict(x_val)\n",
        "predicted_Price= scaleroutput.inverse_transform(predicted_Price)\n",
        "print(predicted_Price.shape)\n",
        "plt.figure()\n",
        "plt.plot(dateval,predicted_Price,label='Pred')\n",
        "plt.plot(dateval,scaleroutput.inverse_transform(y_val),label='Real')\n",
        "plt.legend()\n",
        "#plt.ylim(0, np.max(orig[trainsize+2:-testsize]))\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "predicted_Price = model.predict(x_test)\n",
        "predicted_Price= scaleroutput.inverse_transform(predicted_Price)\n",
        "print(predicted_Price.shape)\n",
        "plt.figure()\n",
        "plt.plot(datetest,predicted_Price[:,-1],label='Pred')\n",
        "plt.plot(datetest,scaleroutput.inverse_transform(y_test)[:,-1],label='Real')\n",
        "plt.legend()\n",
        "#plt.ylim(0, np.max(orig[-testsize:]))\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uhmMw93rnDfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_Price = scaleroutput.inverse_transform(regressor.predict(x_train))\n",
        "orig=train[target_coln]\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(datetrain[-40:],predicted_Price[-40:])\n",
        "plt.plot(datetrain[-40:],orig[-40:])\n",
        "predicted_Price = scaleroutput.inverse_transform(regressor.predict(x_val))\n",
        "orig=val[target_coln]\n",
        "plt.plot(dateval[seq_length:],predicted_Price)\n",
        "plt.plot(dateval[seq_length:],orig[seq_length:])\n",
        "predicted_Price = scaleroutput.inverse_transform(regressor.predict(x_test))\n",
        "orig=test[target_coln]\n",
        "plt.plot(datetest[seq_length:],predicted_Price)\n",
        "plt.plot(datetest[seq_length:],orig[seq_length:])\n",
        "plt.legend(['Pred Train','Train','Pred Val','Val','Pred Test','Test'])\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(datetest,predicted_Price)\n",
        "plt.plot(datetest,orig)\n",
        "plt.legend(['Pred Test','Test'])"
      ],
      "metadata": {
        "id": "riv0M0JqFStO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_Price = scaleroutput.inverse_transform(regressor.predict(x_test))\n",
        "orig=scaleroutput.inverse_transform(y_test)\n",
        "\n",
        "print('Accuracy:', 100 - (100*(abs(orig-predicted_Price)/orig)).mean())\n",
        "\n",
        "plt.plot(orig[0]*predicted_Price/max(predicted_Price), color = 'blue', label = 'Predicted Volume')\n",
        "plt.plot(orig, color = 'lightblue', label = 'Original Volume')\n",
        "\n",
        "plt.title('train Price Predictions')\n",
        "plt.xlabel('Trading Date')\n",
        "plt.ylabel('train Price')\n",
        "\n",
        "plt.legend()\n",
        "fig=plt.gcf()\n",
        "fig.set_figwidth(20)\n",
        "fig.set_figheight(6)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(predicted_Price, color = 'blue', label = 'Predicted Volume')\n",
        "plt.plot(orig, color = 'lightblue', label = 'Original Volume')\n",
        "\n",
        "plt.title('train Price Predictions')\n",
        "plt.xlabel('Trading Date')\n",
        "plt.ylabel('train Price')\n",
        "\n",
        "plt.legend()\n",
        "fig=plt.gcf()\n",
        "fig.set_figwidth(20)\n",
        "fig.set_figheight(6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M21GgTwW4KSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(\n",
        "      LSTM(\n",
        "          # Tune number of units separately.\n",
        "          units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "          activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
        "          return_sequences=True\n",
        "      )\n",
        "  )\n",
        "  model.add(\n",
        "      LSTM(\n",
        "          # Tune number of units separately.\n",
        "          units=hp.Int(\"units1\", min_value=32, max_value=64, step=2),\n",
        "          activation=hp.Choice(\"activation1\", [\"relu\", \"tanh\"]),\n",
        "          return_sequences=False\n",
        "          )\n",
        "      )\n",
        "  if hp.Boolean(\"dropout\"):\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "  model.add(layers.Dense(1))\n",
        "  learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "      loss=\"mse\",\n",
        "      metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "build_model(keras_tuner.HyperParameters())\n",
        "\n",
        "hp = keras_tuner.HyperParameters()\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "  build_model,\n",
        "  hyperparameters=hp,\n",
        "  objective=keras_tuner.Objective(\"accuracy\", direction=\"max\"),\n",
        "  overwrite=True,\n",
        "  max_trials=10,\n",
        "  max_retries_per_trial=3)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=50, batch_size=16,validation_data=(x_val, y_val))\n",
        "tuner.search_space_summary()\n",
        "tuner.results_summary(1)\n",
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "best_model = build_model(tuner.get_best_hyperparameters()[0])\n",
        "best_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\"accuracy\"])\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "best_model.fit(x_train, y_train, epochs=100, batch_size=16,validation_data=(x_val, y_val),callbacks=[early_stop])#, validation_split=0.3\n",
        "best_model.summary()\n",
        "keras.utils.plot_model(best_model,show_shapes=True)\n",
        "\n",
        "predicted_Price = scaleroutput.inverse_transform(best_model.predict(x_test))\n",
        "orig=scaleroutput.inverse_transform(y_test)\n",
        "\n",
        "# Accuracy of the predictions\n",
        "print('Accuracy:', 100 - (100*(abs(orig-predicted_Price)/orig)).mean())\n",
        "\n",
        "\n",
        "plt.plot(orig[0]*predicted_Price/max(predicted_Price), color = 'blue', label = 'Predicted Volume')\n",
        "plt.plot(orig, color = 'lightblue', label = 'Original Volume')\n",
        "\n",
        "plt.title('train Price Predictions')\n",
        "plt.xlabel('Trading Date')\n",
        "plt.ylabel('train Price')\n",
        "\n",
        "plt.legend()\n",
        "fig=plt.gcf()\n",
        "fig.set_figwidth(20)\n",
        "fig.set_figheight(6)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(predicted_Price, color = 'blue', label = 'Predicted Volume')\n",
        "plt.plot(orig, color = 'lightblue', label = 'Original Volume')\n",
        "\n",
        "plt.title('train Price Predictions')\n",
        "plt.xlabel('Trading Date')\n",
        "plt.ylabel('train Price')\n",
        "\n",
        "plt.legend()\n",
        "fig=plt.gcf()\n",
        "fig.set_figwidth(20)\n",
        "fig.set_figheight(6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JNU7qZQppRrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = build_model(tuner.get_best_hyperparameters()[0])\n",
        "a.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "a.fit(x_train, y_train, epochs=1, batch_size=64)\n",
        "a.summary()\n",
        "keras.utils.plot_model(a,show_shapes=True)"
      ],
      "metadata": {
        "id": "BkSiXv3HhWUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "seq_length = 2\n",
        "target = 'Close'\n",
        "dayspan = 90\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "train = data\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "test = train.tail(dayspan)\n",
        "train = train.iloc[:-dayspan]\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "target_col = target\n",
        "features = train.columns\n",
        "X = train[features].values\n",
        "y = train[target_col].values\n",
        "dx = test[features].values\n",
        "dy = test[target_col].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "scaler = MinMaxScaler()\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "dx = scaler.transform(dx)\n",
        "y_train = scaler1.fit_transform(y_train.reshape(-1,1))\n",
        "y_test = scaler1.transform(y_test.reshape(-1,1))\n",
        "\n",
        "X_train_seq, temp = create_sequences(X_train[:-1], seq_length)\n",
        "y_train_seq, temp = create_sequences(y_train, seq_length)\n",
        "X_test_seq, temp = create_sequences(X_test[:-1], seq_length)\n",
        "y_test_seq, temp = create_sequences(y_test, seq_length)\n",
        "dxx, dyy = create_sequences(dx, seq_length)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(75, activation='relu', input_shape=(seq_length, len(features))))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "model.compile(optimizer=opt, loss='mean_squared_error',metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True)\n",
        "history = model.fit(X_train_seq, y_train[3:], epochs=500, batch_size=64,validation_data=(X_test_seq, y_test[3:]),callbacks=[early_stop])#, validation_split=0.3\n",
        "print(X_train_seq.shape,y_train_seq.shape,y_train.shape)\n",
        "\n",
        "scale=MinMaxScaler()\n",
        "scale.min_,scale.scale_=scaler.min_[0],scaler.scale_[0]\n",
        "\n",
        "predbest = scale.inverse_transform(model.predict(dxx))\n",
        "predbest = predbest.reshape(-1,1)\n",
        "real_prices = dy[:-seq_length]\n",
        "\n",
        "days = list(range(1, dayspan-seq_length+1))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(days, real_prices[0]*predbest/max(predbest), label=\"Predicted Prices\", marker='o', linestyle='-', color='b')\n",
        "#plt.plot(days, predbest, label=\"Predicted normal Prices\", marker='o', linestyle='-', color='b')\n",
        "plt.plot(days, real_prices, label=\"Real Prices\", marker='x', linestyle='-', color='g')\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"train Price\")\n",
        "plt.title(\"Predicted vs. Real train Prices\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(days, predbest, label=\"Predicted normal Prices\", marker='o', linestyle='-', color='b')\n",
        "plt.plot(days, real_prices, label=\"Real Prices\", marker='x', linestyle='-', color='g')\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"train Price\")\n",
        "plt.title(\"Predicted vs. Real train Prices\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YyJP4Kpg5hJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "from pandas_datareader import data as pdr\n",
        "from collections import deque\n",
        "import random\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "jZN7ZHHmmLhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f= predbest.copy()\n",
        "name = 'Q-learning agent'\n",
        "class Agent:\n",
        "    def __init__(self, state_size, window_size, trend, skip, batch_size):\n",
        "        self.state_size = state_size\n",
        "        self.window_size = window_size\n",
        "        self.half_window = window_size // 2\n",
        "        self.trend = trend\n",
        "        self.skip = skip\n",
        "        self.action_size = 3\n",
        "        self.batch_size = batch_size\n",
        "        self.memory = deque(maxlen = 1000)\n",
        "        self.inventory = []\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 0.5\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.999\n",
        "        tf.reset_default_graph()\n",
        "        self.sess = tf.InteractiveSession()\n",
        "        self.X = tf.placeholder(tf.float32, [None, self.state_size])\n",
        "        self.Y = tf.placeholder(tf.float32, [None, self.action_size])\n",
        "        feed = tf.layers.dense(self.X, 256, activation = tf.nn.relu)\n",
        "        self.logits = tf.layers.dense(feed, self.action_size)\n",
        "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
        "        self.optimizer = tf.train.GradientDescentOptimizer(1e-5).minimize(\n",
        "            self.cost\n",
        "        )\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def act(self, state):\n",
        "        if random.random() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        return np.argmax(\n",
        "            self.sess.run(self.logits, feed_dict = {self.X: state})[0]\n",
        "        )\n",
        "\n",
        "    def get_state(self, t):\n",
        "        window_size = self.window_size + 1\n",
        "        d = t - window_size + 1\n",
        "        block = self.trend[d : t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0 : t + 1]\n",
        "        res = []\n",
        "        for i in range(window_size - 2):\n",
        "            res.append(block[i + 1] - block[i])\n",
        "        return np.array([res])\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        mini_batch = []\n",
        "        l = len(self.memory)\n",
        "        for i in range(l - batch_size, l):\n",
        "            mini_batch.append(self.memory[i])\n",
        "        replay_size = len(mini_batch)\n",
        "        X = np.empty((replay_size, self.state_size))\n",
        "        Y = np.empty((replay_size, self.action_size))\n",
        "        states = np.array([a[0][0] for a in mini_batch])\n",
        "        new_states = np.array([a[3][0] for a in mini_batch])\n",
        "        Q = self.sess.run(self.logits, feed_dict = {self.X: states})\n",
        "        Q_new = self.sess.run(self.logits, feed_dict = {self.X: new_states})\n",
        "        for i in range(len(mini_batch)):\n",
        "            state, action, reward, next_state, done = mini_batch[i]\n",
        "            target = Q[i]\n",
        "            target[action] = reward\n",
        "            if not done:\n",
        "                target[action] += self.gamma * np.amax(Q_new[i])\n",
        "            X[i] = state\n",
        "            Y[i] = target\n",
        "        cost, _ = self.sess.run(\n",
        "            [self.cost, self.optimizer], feed_dict = {self.X: X, self.Y: Y}\n",
        "        )\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "        return cost\n",
        "\n",
        "    def buy(self, initial_money):\n",
        "        starting_money = initial_money\n",
        "        states_sell = []\n",
        "        states_buy = []\n",
        "        inventory = []\n",
        "        state = self.get_state(0)\n",
        "        for t in range(0, len(self.trend) - 1, self.skip):\n",
        "            action = self.act(state)\n",
        "            next_state = self.get_state(t + 1)\n",
        "            if action == 1 and initial_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
        "                inventory.append(self.trend[t])\n",
        "                initial_money -= self.trend[t]\n",
        "                states_buy.append(t)\n",
        "                print('day %d: buy 1 unit at price %f, total balance %f'% (t, self.trend[t], initial_money))\n",
        "            elif action == 2 and len(inventory):\n",
        "                bought_price = inventory.pop(0)\n",
        "                initial_money += self.trend[t]\n",
        "                states_sell.append(t)\n",
        "                try:\n",
        "                    invest = ((close[t] - bought_price) / bought_price) * 100\n",
        "                except:\n",
        "                    invest = 0\n",
        "                print(\n",
        "                    'day %d, sell 1 unit at price %f, investment %f %%, total balance %f,'\n",
        "                    % (t, close[t], invest, initial_money)\n",
        "                )\n",
        "            state = next_state\n",
        "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
        "        total_gains = initial_money - starting_money\n",
        "        return states_buy, states_sell, total_gains, invest\n",
        "\n",
        "    def train(self, iterations, checkpoint, initial_money):\n",
        "      for i in range(iterations):\n",
        "          total_profit = 0\n",
        "          inventory = []\n",
        "          state = self.get_state(0)\n",
        "          starting_money = initial_money\n",
        "          cost = 0  # Initialize 'cost' outside the loop\n",
        "          for t in range(0, len(self.trend) - 1, self.skip):\n",
        "              action = self.act(state)\n",
        "              next_state = self.get_state(t + 1)\n",
        "              if action == 1 and starting_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
        "                  inventory.append(self.trend[t])\n",
        "                  starting_money -= self.trend[t]\n",
        "              elif action == 2 and len(inventory) > 0:\n",
        "                  bought_price = inventory.pop(0)\n",
        "                  total_profit += self.trend[t] - bought_price\n",
        "                  starting_money += self.trend[t]\n",
        "              invest = ((starting_money - initial_money) / initial_money)\n",
        "              self.memory.append((state, action, invest, next_state, starting_money < initial_money))\n",
        "              state = next_state\n",
        "              batch_size = min(self.batch_size, len(self.memory))\n",
        "              cost = self.replay(batch_size)\n",
        "          if (i+1) % checkpoint == 0:\n",
        "              print(f'epoch: {i + 1}, total rewards: {total_profit:.3f}, cost: {cost}, total money: {starting_money}')\n",
        "\n"
      ],
      "metadata": {
        "id": "B3GOGtNxAEj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "close = orig.T\n",
        "initial_money = 10000\n",
        "window_size = 90\n",
        "skip = 2\n",
        "batch_size = 32\n",
        "agent = Agent(state_size = window_size,\n",
        "              window_size = window_size,\n",
        "              trend = close,\n",
        "              skip = skip,\n",
        "              batch_size = batch_size)\n",
        "agent.train(iterations = 200, checkpoint = 10, initial_money = initial_money)"
      ],
      "metadata": {
        "id": "Lovh5Pe4mBL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states_buy, states_sell, total_gains, invest = agent.buy(initial_money = initial_money)"
      ],
      "metadata": {
        "id": "x7YeIPt7mCMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (15,5))\n",
        "plt.plot(close, color='r', lw=2.)\n",
        "plt.plot(close, '^', markersize=10, color='m', label = 'buying signal', markevery = states_buy)\n",
        "plt.plot(close, 'v', markersize=10, color='k', label = 'selling signal', markevery = states_sell)\n",
        "plt.title('total gains %f, total investment %f%%'%(total_gains, invest))\n",
        "#plt.legend()\n",
        "plt.savefig(name+'.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9AJDk8lZmG-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnNrDavdt1II"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
