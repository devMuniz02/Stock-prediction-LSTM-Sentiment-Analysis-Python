{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_MH7-9PeFlW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q gnews==0.3.5 newspaper3k\n",
    "!pip install --upgrade requests urllib3 chardet charset_normalizer\n",
    "\n",
    "import warnings\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from gnews import GNews\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# API Configuration\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
    "HEADERS = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "# Query Hugging Face Sentiment API\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Save Sentiment Data\n",
    "def save_sentiment(start, end, topic, filename):\n",
    "    # Initialize Google News API\n",
    "    google_news = GNews()\n",
    "    google_news.exclude_websites = [\n",
    "        'costar.com', 'investorplace', 'teslaoracle', 'barrons', 'bizjournals',\n",
    "        'forbes', 'pymnts', 'thestreet', 'investing', 'mining', 'statecollege',\n",
    "        'realmoney.thestreet', 'fastcompany', 'crainsnewyork', 'investors'\n",
    "    ]\n",
    "    google_news.country = 'United States'\n",
    "    google_news.language = 'english'\n",
    "    google_news.start_date = start\n",
    "    google_news.end_date = end\n",
    "\n",
    "    # Fetch news articles\n",
    "    articles = google_news.get_news(topic)\n",
    "    sentiments = []\n",
    "\n",
    "    for article in articles:\n",
    "        full_article = google_news.get_full_article(article['url'])\n",
    "        if not full_article or not full_article.publish_date:\n",
    "            continue\n",
    "\n",
    "        # Query title and text sentiment\n",
    "        title_sentiment = query_with_retries(full_article.title)\n",
    "        content = \" \".join(full_article.text.split()[:300])\n",
    "        text_sentiment = query_with_retries(content)\n",
    "\n",
    "        if title_sentiment and text_sentiment and full_article.publish_date is not None:\n",
    "            sentiments.append({\n",
    "                \"Date\": full_article.publish_date.date().isoformat(),\n",
    "                \"NegTitle\": extract_score(title_sentiment, 'negative'),\n",
    "                \"NeuTitle\": extract_score(title_sentiment, 'neutral'),\n",
    "                \"PosTitle\": extract_score(title_sentiment, 'positive'),\n",
    "                \"NegText\": extract_score(text_sentiment, 'negative'),\n",
    "                \"NeuText\": extract_score(text_sentiment, 'neutral'),\n",
    "                \"PosText\": extract_score(text_sentiment, 'positive')\n",
    "            })\n",
    "\n",
    "    # Check if sentiments were collected\n",
    "    if not sentiments:\n",
    "        print(f\"No sentiments collected for {topic} between {start} and {end}.\")\n",
    "        return\n",
    "\n",
    "    # Create DataFrame and save\n",
    "    df = pd.DataFrame(sentiments)\n",
    "    if 'Date' not in df.columns:\n",
    "        print(f\"'Date' column missing in DataFrame. Collected data: {df.head()}\")\n",
    "        return\n",
    "\n",
    "    df = df.groupby('Date').mean().reset_index()\n",
    "    df.to_csv(f\"{filename}.csv\", index=False)\n",
    "\n",
    "# Helper function for retries\n",
    "def query_with_retries(payload, max_retries=3):\n",
    "    for _ in range(max_retries):\n",
    "        response = query(payload)\n",
    "        if isinstance(response, list):\n",
    "            return response\n",
    "    return None\n",
    "\n",
    "# Helper function to extract sentiment score\n",
    "def extract_score(sentiment_data, label):\n",
    "    for item in sentiment_data[0]:\n",
    "        if item['label'] == label:\n",
    "            return item['score']\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxalMXRqhuv9",
    "outputId": "f3d304e2-f83f-4e7a-fc64-ed45638aebf7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent = [\n",
    "    'Jan2022', 'Feb2022', 'Mar2022'\n",
    "]\n",
    "\n",
    "# Define start and end dates for each month\n",
    "dates = [\n",
    "    ((2022, 1, 1), (2022, 2, 1)),\n",
    "    ((2022, 2, 1), (2022, 3, 1)),\n",
    "    ((2022, 3, 1), (2022, 4, 1))\n",
    "]\n",
    "\n",
    "# Loop through each date range and save sentiment\n",
    "for i, date_range in enumerate(dates):\n",
    "    start_date, end_date = date_range\n",
    "    save_sentiment(start_date, end_date, 'TSLA', 'TSLA' + sent[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
